{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big Data - Aula 5 - parte 2 \n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algoritmic Concepts and Distributed Computing Challenges\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1) Graph Based Data - Inverted Indexing\n",
    "----\n",
    "\n",
    "An inverted index is a data structure that makes it easy, given a term, to find (pointers to) all the places where that term occurs.\n",
    "\n",
    "\n",
    "<img src=\"images/inv_index.png\" style=\"width:70%\" />\n",
    "\n",
    "\n",
    "### Vamos implementar um inverted index?\n",
    "\n",
    "Considerem o seguinte texto, dividido por pontos finais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = \"In statistics, maximum likelihood estimation(MLE) is a method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters. MLE can be seen as a special case of the maximum a posteriori estimation(MAP) that assumes a uniform prior distribution of the parameters, or as a variant of the MAP that ignores the prior and which therefore is unregularized. The method of maximum likelihood corresponds to many well-known estimation methods in statistics. For example, one may be interested in the heights of adult female penguins, but is unable to measure the height of every single penguin in a population due to cost or time constraints. Assuming that the heights are normally distributed with some unknown mean and variance, the mean and variance can be estimated with MLE while only knowing the heights of some sample of the overall population. MLE would accomplish this by taking the mean and variance as parameters and finding particular parametric values that make the observed results the most probable given the model. In general, for a fixed set of data and underlying statistical model, the method of maximum likelihood selects the set of values of the model parameters that maximizes the likelihood function. Intuitively, this maximizes the 'agreement' of the selected model with the observed data, and for discrete random variables it indeed maximizes the probability of the observed data under the resulting distribution. Maximum likelihood estimation gives a unified approach to estimation, which is well-defined in the case of the normal distribution and many other problems.\"\n",
    "\n",
    "raw_list = raw.split(\".\")\n",
    "len(raw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In statistics, maximum likelihood estimation(MLE) is a method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{}.\".format(raw_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' MLE can be seen as a special case of the maximum a posteriori estimation(MAP) that assumes a uniform prior distribution of the parameters, or as a variant of the MAP that ignores the prior and which therefore is unregularized.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{}.\".format(raw_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in': {0: True, 1: True}, 'likelihood': {1: True}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'in': [0, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_index = {}\n",
    "i_index[\"in\"] = {}\n",
    "i_index[\"likelihood\"] = {}\n",
    "i_index[\"in\"][0] = True #word in, appears in doc 0, 1 time\n",
    "i_index[\"likelihood\"][1] = True #word in, appears in doc 1, 1 time\n",
    "i_index[\"in\"][1] = True\n",
    "\n",
    "print(i_index)\n",
    "\n",
    "j_index = {}\n",
    "j_index[\"in\"] = []\n",
    "j_index[\"in\"].append(0)\n",
    "j_index[\"in\"].append(1)\n",
    "i_index[\"likelihood\"][1] = True\n",
    "j_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalho de Casa 1\n",
    "\n",
    "1) Implement in python a function i_index_gen() that given as input a set of documents (an array of strings) returns an  inverted index based. Clean the text from punctuations chars or upper letters. \n",
    "\n",
    "2) Make a second function that returns the same i_index based on a pandas DataFrame without indexes\n",
    "\n",
    "3) Make a third function that returns the same i_index based on a pandas DataFrame using indexes\n",
    "\n",
    "4) Compare the performance for the three methods using ```%%time``` (you should increase your text example) and take your conclusions how lists, DataFrames (with or without indexes) manage searches\n",
    "\n",
    "\n",
    "**Don't forget to**\n",
    "- present all results in a python notebook;\n",
    "- Comment your code;\n",
    "\n",
    "Good Luck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.4 ms ± 3.11 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "----\n",
      "3.88 ms ± 463 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Example on the usage of %timeit\n",
    "import math\n",
    "%timeit [math.cos((i/2**i)**3) for i in range(1,10000)]\n",
    "print(\"----\")\n",
    "%timeit [(i)**3 for i in range(1,10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ola\n",
      "CPU times: user 216 µs, sys: 97 µs, total: 313 µs\n",
      "Wall time: 264 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"ola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Problems in Big Data Scenario?\n",
    "\n",
    "---\n",
    "\n",
    "- Inverted indexing is fundamentally a very large search problem.\n",
    "- Again, problems arise when data does not fit in memory or a single CPU is too short.\n",
    "- How to deal with millions of files or a giant ```i_index```? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2) Graph Based Algorithms\n",
    "\n",
    "##  Page Rank Applications\n",
    "\n",
    "#### Basic Idea: Links as votes for Ranking pages\n",
    "\n",
    "Each link’s vote is proportional to the importance of its source page\n",
    "\n",
    "- If page $j$ with importance $r_j$ has $n$ out-links, each link gets $r_j / n_j$ votes\n",
    "- Page $j$’s own importance is the sum of the votes on its in-links (I) (A page is important if it is pointed to by other important pages)\n",
    "\n",
    "So, for a single page $j$, its importance $r_j$ is given by:\n",
    "\n",
    "$$r_j = \\sum_{i=1}^{I} \\frac{r_i}{n_i}$$\n",
    "\n",
    "---\n",
    "\n",
    "Take a first set of 3 nodes:\n",
    "\n",
    "<img src=\"images/page_rank.png\" style=\"width:30%\"/>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's write the equations, starting in $y$:\n",
    "\n",
    "$$r_y =r_y/2+r_a/2 $$\n",
    "\n",
    "$$r_a =r_y/2+r_m$$ \n",
    "\n",
    "$$r_m =r_a /2$$\n",
    "\n",
    "Is this solvable? What is wrong? The underlying matrix is $Singular$. \n",
    "We need a fourth equation to give this a solution:\n",
    "\n",
    "$$r_m + r_a + r_y = 1$$\n",
    "---\n",
    "\n",
    "\n",
    "Let's build a matrix M where this equations are represented in the following order (both rows and columns) $[y, a, m]$\n",
    "Our system (Homogenous) is then \n",
    "\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} \n",
    "1/2 & -1/2 & 0\\\\\n",
    "-1/2 & 1 & -1\\\\\n",
    "0 & -1/2 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\begin{bmatrix} \n",
    "y\\\\\n",
    "a\\\\\n",
    "m\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix} \n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5 -0.5  0. ]\n",
      " [-0.5  1.  -1. ]\n",
      " [ 0.  -0.5  1. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "M = np.array([[0.5, -0.5, 0],\n",
    "[-0.5, 1, -1],\n",
    "[0, -0.5, 1]])\n",
    "print(M)\n",
    "\n",
    "np.linalg.det(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have to add an extra relation between parameters: for instance, a normalization information their relative values like $ y+a+m = 1$, which means a = 1-y-m. Let's use this in the last equation, obtaining $(y+m-1)/2 + m = 0 <=> y/2 + 3/2m  = 1/2$.\n",
    "\n",
    "\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} \n",
    "1/2 & -1/2 & 0\\\\\n",
    "-1/2 & 1 & -1\\\\\n",
    "1/2 & 0 & 3/2\\\\\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\begin{bmatrix} \n",
    "y\\\\\n",
    "a\\\\\n",
    "m\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix} \n",
    "0\\\\\n",
    "0\\\\\n",
    "1/2\\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4],\n",
       "       [ 0.4],\n",
       "       [ 0.2]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.array([[0.5, -0.5, 0],\n",
    "[-0.5, 1, -1],\n",
    "[1/2, 0, 3/2]])\n",
    "\n",
    "#np.linalg.inv(M)\n",
    "b= np.array([[0], [0], [1/2]])\n",
    "\n",
    "X = np.linalg.solve(M,b)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now if M is huge?\n",
    "linalg uses gaussian elimination. this is not good for huge matrices (Big Data).\n",
    "\n",
    "Inverting huge matrices is a very relvant subject in general. Also here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIGDATA ALGORITHM: POWER ITERATION\n",
    "\n",
    "## Matrix vector Multiplication (e.g. Page Rank)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw before, Gaussian elimination method works for small examples, but we need a better method for large web-size graphs\n",
    "\n",
    "\n",
    "So, for a single page $j$, its importance $r_j$ is given by:\n",
    "\n",
    "$$r_j = \\sum_{i=1}^{I} \\frac{r_i}{n_i}$$\n",
    "\n",
    "---\n",
    "\n",
    "Take a first set of 3 nodes:\n",
    "\n",
    "<img src=\"images/page_rank.png\" style=\"width:30%\"/>\n",
    "\n",
    "\n",
    "Could be written as \n",
    "\n",
    "$$r_y =r_y/2+r_a/2 $$\n",
    "\n",
    "$$r_a =r_y/2+r_m$$ \n",
    "\n",
    "$$r_m =r_a /2$$\n",
    "\n",
    "\n",
    "We have to add an extra relation between parameters: for instance, a normalization information their relative values like $ y+a+m = 1$, which means a = 1-y-m. \n",
    "\n",
    "\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} \n",
    "1/2 & -1/2 & 0\\\\\n",
    "-1/2 & 1 & -1\\\\\n",
    "1/2 & 0 & 3/2\\\\\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\begin{bmatrix} \n",
    "y\\\\\n",
    "a\\\\\n",
    "m\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix} \n",
    "0\\\\\n",
    "0\\\\\n",
    "1/2\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about if this matrix is HUGE?\n",
    "\n",
    "To solve this problem let's move back again to the original formulation and consider the matrix $M$ with dimensions D by D where D = number of web pages and  where $M_{ij}$ is given by \n",
    "\n",
    "``` If i == j then ```  \n",
    "\n",
    "$ \\space\\space\\space M_{ij} = 1/d_i$\n",
    "\n",
    "``` else```\n",
    "\n",
    "$ \\space\\space\\space M_{ij} =  0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $d_i$ are the number of outbound links;\n",
    "\n",
    "This is exactly the right side of \n",
    "\n",
    "\n",
    "$$r_y =r_y/2+r_a/2 $$\n",
    "\n",
    "$$r_a =r_y/2+r_m$$ \n",
    "\n",
    "$$r_m =r_a /2$$\n",
    "\n",
    "This relations are called the **flow equations** and they could be written as \n",
    "\n",
    "$$r = Mr$$\n",
    "\n",
    "where $r = [r_a r_y r_m]^T$ which are the page ratings.\n",
    "\n",
    "Suppose page $i$ links to 3 pages, including $j$, we the flow equation states that $r_j = \\sum_{i=1}^{I} \\frac{r_i}{n_i}$.\n",
    "\n",
    "\n",
    "<img src=\"images/flow_equation.png\" style=\"width:60%\"/>\n",
    "\n",
    "\n",
    "If $Mr = r$ this means $Mr = Ir = \\lambda r$\n",
    "\n",
    "This means $r$ is a so called eigenvector of $M$ \n",
    "Actually, since $||\\sum_i(M_{ij})|| < 1$ (due to normalization) and since $\\lambda=1$, then $r$ is the biggest eigenvalue of $M$.\n",
    "\n",
    "> $x$ is an eigenvector of $A$ if $Ax = \\lambda x$ where $\\lambda$ is a real constant \n",
    "\n",
    "----\n",
    "\n",
    "## Power iteration: \n",
    "### A simple iterative scheme to find the dominant eigenvector (r)\n",
    "\n",
    "- Suppose there are N web pages\n",
    "- Initialize: $r^{(0)} = [1/N,....,1/N]^T$\n",
    "\n",
    "> This means all rankings are considered equal at the begining.\n",
    "\n",
    "- Iterate: $r^{(t+1)} = M.r^{(t)}$\n",
    "  \n",
    "- Stop when $\\|r(t+1) – r(t)\\| < ε$\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "## How it Works?\n",
    "\n",
    "$r^{(2)} = Mr^{(1)} = M(Mr^{(0)}) = M^2r^{(1)}$\n",
    "\n",
    "Claim: $M^k r^{(1)} \\rightarrow r$\n",
    "\n",
    "\n",
    "### Proof:\n",
    "$r$ could be written using a linear combination of the M eigenvectors x_1,...x_n (all). That means:\n",
    "\n",
    "$$r^{(0)} = c_1 x_1 + c_2 x_2 + ... + c_n x_n$$\n",
    "\n",
    "then\n",
    "\n",
    "$$Mr^{(0)} = M(c_1 x_1 + c_2 x_2 + ... + c_n x_n) = c_1 \\lambda_1 x_1 + c_2 \\lambda_2 x_2 + ... + c_n \\lambda_n x_n$$\n",
    "\n",
    "finally\n",
    "\n",
    "$$M^k r^{(0)} = c_1(\\lambda_1^k x_1) + c_2(\\lambda_2^k x_2) + ... + c_n(\\lambda_n^k x_n)$$\n",
    "\n",
    "since all $\\lambda$s (eigenvalues) are $<1$ besides $\\lambda_1=1$ (the one we want), when $k -> \\inf$\n",
    "\n",
    "$$M^k r^{(0)} -> c_1(x_1)$$\n",
    "\n",
    "But since $Mr = r$ for the right $r$, then $c_1 = 1 $\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Random Web Surfer Interpretation\n",
    "\n",
    "\n",
    "Imagine a random web surfer\n",
    "\n",
    "- At any time $n$ surfer is on some page $i$ \n",
    "- At time $n+1$, the surfer follows an out-link from $i$ uniformly at random \n",
    "- Ends up on some page $j$ linked from $i$\n",
    "- Process repeats indefinitely\n",
    "\n",
    "\n",
    "$r_j = \\sum_{i=1}^{N} \\frac{r_i}{n_i}$\n",
    "\n",
    "Consider $p(n)$ as the probability distribution of the websurfer at time $n$\n",
    "\n",
    "**What is the probability of the web surfer to be in the page $j$ at time $n+1$?**\n",
    "\n",
    "<img src=\"images/page_rank_as_prob.png\" style=\"width:40%\"/>\n",
    "\n",
    "Since we are navigating from anywhere, it depends on the probabilities of being in $i_1$, $i_2$ or $i_3$ at the previous step (n), and then, at random ($1/d_i$) jump to this page. That is,\n",
    "\n",
    "$$p(n+1) = M p(n)$$\n",
    "\n",
    "Suppose now that we reach \n",
    "\n",
    "$$p(n+1) = M p(n) = p(n)$$\n",
    "\n",
    "Which means, the probability distribution is not altered anymore by new steps. Then $p(t)$ is said to be a **stationary distribution of a random walk**.\n",
    "\n",
    "### Some Remarks\n",
    "\n",
    "- If we solve $p(n)$, random web surfer probability map, we can find or original $r$ vector (rank vector for each page). \n",
    "- So, each time we multiply $M$ by $r^k$ ($Mr^k$) we are calculating a new $p(n+1)$. \n",
    "- Each row in M takes the role of probabiltiy distribution to go from previous positions to new positions at n+1 time.\n",
    "\n",
    "** This was Google problem to be solved back in 1998. ***\n",
    "\n",
    "Let us finally see some issues to define the final equation to be solved.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues to solve the Final Problem\n",
    "\n",
    "**2 problems when solving the random walking problem**\n",
    "\n",
    "(1) Some pages are **dead ends** (have no out-links)\n",
    ">    Random walk has “nowhere” to go to\n",
    ">  - this leaks the resulting ranks\n",
    "\n",
    "(2) **Spider traps** (all out-links are within the group)\n",
    ">  Random walked gets “stuck” in a trap\n",
    ">  - And eventually spider traps absorb all importance\n",
    "  \n",
    "<img src=\"images/page_rank_probs.png\" style=\"width:30%\"/>\n",
    "\n",
    "\n",
    "**Google Solved this With Random TelePorts - Some times we should just randomly jump out to any other page to avoid dead ends and spider traps**\n",
    "\n",
    "\n",
    "Consider this random jump is done with probability $1-\\beta$ and not done with probability $\\beta$. \n",
    "This means each line of M has not zeros it allways have some probability of jumping to an unexpected page!\n",
    "\n",
    "The new flow equation is now:\n",
    "\n",
    "$$r_j = \\beta \\sum_i \\frac{r_i}{d_i} + (1-\\beta)\\frac{1}{N}$$\n",
    "\n",
    "\n",
    "\n",
    "And the new Google Matrix A is:\n",
    "\n",
    "$$A = \\beta M + (1-\\beta) \\left[\\frac{1}{N} \\right]_{N \\times N}$$\n",
    "$$ $$\n",
    "<div style=\"text-align:center\">[Brin-Page, ‘98]</div>\n",
    "\n",
    "http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, applying to Page Rank Calculation\n",
    "\n",
    "Key step is the following matrix-vector multiplication:\n",
    "\n",
    "$$r_{new} =A r_{old}$$\n",
    "\n",
    "This is easy if we have enough main memory to hold $A, r_{old}, r_{new}$\n",
    "\n",
    "Say N = 1 billion pages   \n",
    "We need 4 bytes for each entry (typical...)\n",
    "\n",
    "- aprox 8GB for each vector, that's high but solvable..\n",
    "\n",
    "- BUT Matrix A has N^2 entries where $N = 10^9$ -->   $10^{18}$ is a large number (plus 4 Bytes per entry!)\n",
    "\n",
    "This is infeasible. The final page rank equation should be: \n",
    "\n",
    "$$r_{new} = \\beta M r_{old} + \\left[\\frac{1-\\beta}{N} \\right]_{N \\times 1}$$\n",
    "\n",
    "\n",
    "M is sparse, so everything is feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2) Matrix Multiplication\n",
    "\n",
    "Matrix multiplication is used for almost any machine learning model creation since most methods are nowadays stronlgy supported by linear algebra.\n",
    "\n",
    "For instance: \n",
    "\n",
    "- Distance measure;\n",
    "- Gradient Calculation;\n",
    "- Graph Calculation;\n",
    "\n",
    "Let's look an example in distance measure between x points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.round(np.random.random([4,4])*100)\n",
    "A = np.tril(A)\n",
    "\n",
    "print(A)\n",
    "b = np.ones([4,1])*2\n",
    "print(b)\n",
    "\n",
    "np.matmul(A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "#### Problems in Big Data Scenario?\n",
    "\n",
    "---\n",
    "\n",
    "- If Initial Matrix too large for memory? Apply a row multiplication per node!?\n",
    "\n",
    "- If not even a single line is able to be fitted in memory? Notice that each input in the resulting vector depends entirely on a single line of the matrix\n",
    "\n",
    "<img src=\"./images/matmul.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do this applies to distance calculation?\n",
    "\n",
    "How to calculate the distance between this two points (a,b) in $R^N$?\n",
    "\n",
    "\n",
    "$$D(\\vec{a},\\vec{b}) = \\sqrt{(a_x^2 - b_x^2) + (a_y^2 - b_y^2) + ...} = \\sqrt{\\sum_i^N{\\Delta ab_i ^2}} $$\n",
    "\n",
    "This is the so called Norm2 distance. There are others like Norm1 (Manhathan distance) where $D(a,b) = \\sum_i^{N}{|\\Delta ab_i|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a matrix \n",
    "\n",
    "\n",
    "$$W =  \\begin{bmatrix}\n",
    "    2 & -1 \\\\\n",
    "    5 & 1 \\\\\n",
    "    6 & 9 \\\\\n",
    "    -2 & 3    \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    a \\\\\n",
    "    b \\\\\n",
    "    c \\\\\n",
    "    d \\\\    \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Let's compute the norm2 between each pair of points using normal programming techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  1],\n",
       "       [ 5,  1],\n",
       "       [ 6,  9],\n",
       "       [-2,  3]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, math\n",
    "W = [[2, 1], [5,1], [6,9], [-2,3]]\n",
    "W = np.array(W)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NW = []\n",
    "for w1 in W:\n",
    "    NW.append([])\n",
    "    for w2 in W:\n",
    "        NW[-1].append(0)\n",
    "        for d in range(len(W[0])):\n",
    "            NW[-1][-1] += (w1[d]-w2[d])**2\n",
    "        NW[-1][-1] = math.sqrt(NW[-1][-1])\n",
    "        \n",
    "M = np.array(NW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           3.           8.94427191   4.47213595]\n",
      " [  3.           0.           8.06225775   7.28010989]\n",
      " [  8.94427191   8.06225775   0.          10.        ]\n",
      " [  4.47213595   7.28010989  10.           0.        ]]\n",
      "----------------\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(M)\n",
    "print(\"----------------\")\n",
    "print(M-M.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   3.        ,   8.94427191,   4.47213595],\n",
       "       [  3.        ,   0.        ,   8.06225775,   7.28010989],\n",
       "       [  8.94427191,   8.06225775,   0.        ,  10.        ],\n",
       "       [  4.47213595,   7.28010989,  10.        ,   0.        ]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.zeros((W.shape[0],W.shape[0]))\n",
    "\n",
    "for d in range(W.shape[1]):\n",
    "    w = np.repeat(W[:,d].reshape(-1,1),W.shape[0], axis=1)\n",
    "    M += (w-w.T)**2\n",
    "np.sqrt(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69168128,  0.95795148],\n",
       "       [ 0.69728775,  0.58615352],\n",
       "       [ 0.03548373,  0.96888841],\n",
       "       ..., \n",
       "       [ 0.27724978,  0.92632415],\n",
       "       [ 0.23730736,  0.81649573],\n",
       "       [ 0.57104187,  0.10000069]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.random([10000,2])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.58875073  0.78891475 ...,  0.17017593  0.0838973\n",
      "   0.89904977]\n",
      " [ 0.58875073  0.          0.65226429 ...,  0.50255283  0.50536241\n",
      "   0.74941776]\n",
      " [ 0.78891475  0.65226429  0.         ...,  0.61887957  0.73582055\n",
      "   0.11302332]\n",
      " ..., \n",
      " [ 0.17017593  0.50255283  0.61887957 ...,  0.          0.12752133\n",
      "   0.72933304]\n",
      " [ 0.0838973   0.50536241  0.73582055 ...,  0.12752133  0.          0.84764047]\n",
      " [ 0.89904977  0.74941776  0.11302332 ...,  0.72933304  0.84764047  0.        ]]\n",
      "CPU times: user 2.92 s, sys: 9.23 ms, total: 2.93 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NW = []\n",
    "for w1 in W:\n",
    "    NW.append([])\n",
    "    for w2 in W:\n",
    "        NW[-1].append(0)\n",
    "        for d in range(len(W[0])):\n",
    "            NW[-1][-1] += (w1[d]-w2[d])**2\n",
    "        NW[-1][-1] = math.sqrt(NW[-1][-1])\n",
    "        \n",
    "M = np.array(NW)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.37184023  0.65628869 ...,  0.41563657  0.47588379\n",
      "   0.86639103]\n",
      " [ 0.37184023  0.          0.76450674 ...,  0.54050713  0.51443123\n",
      "   0.5022774 ]\n",
      " [ 0.65628869  0.76450674  0.         ...,  0.2454843   0.25289584\n",
      "   1.02068035]\n",
      " ..., \n",
      " [ 0.41563657  0.54050713  0.2454843  ...,  0.          0.11686607\n",
      "   0.87699729]\n",
      " [ 0.47588379  0.51443123  0.25289584 ...,  0.11686607  0.          0.7904074 ]\n",
      " [ 0.86639103  0.5022774   1.02068035 ...,  0.87699729  0.7904074   0.        ]]\n",
      "CPU times: user 5.95 s, sys: 2.44 s, total: 8.38 s\n",
      "Wall time: 8.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = np.zeros((W.shape[0],W.shape[0]))\n",
    "\n",
    "for d in range(W.shape[1]):\n",
    "    w = np.repeat(W[:,d].reshape(-1,1),W.shape[0], axis=1)\n",
    "    m += (w-w.T)**2\n",
    "    \n",
    "M = np.sqrt(m)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#W = np.random.random([1000,2])\n",
    "w = (np.repeat(W.reshape(-1,1,W.shape[1]),W.shape[0], axis=1)-np.repeat(W.reshape(1,-1,W.shape[1]),W.shape[0], axis=0))**2\n",
    "M = np.sum(w, axis=2)\n",
    "print(M)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
